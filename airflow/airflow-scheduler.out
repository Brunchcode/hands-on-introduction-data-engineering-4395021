[[34m2024-04-22T14:30:25.809+0000[0m] {[34mscheduler_job_runner.py:[0m788} INFO[0m - Starting the scheduler[0m
[[34m2024-04-22T14:30:25.809+0000[0m] {[34mscheduler_job_runner.py:[0m795} INFO[0m - Processing each file at most -1 times[0m
[[34m2024-04-22T14:30:25.814+0000[0m] {[34mmanager.py:[0m165} INFO[0m - Launched DagFileProcessorManager with pid: 12628[0m
[[34m2024-04-22T14:30:25.815+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2024-04-22T14:30:25.818+0000[0m] {[34msettings.py:[0m60} INFO[0m - Configured default timezone Timezone('UTC')[0m
[2024-04-22T14:30:25.837+0000] {manager.py:411} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[[34m2024-04-22T14:32:07.343+0000[0m] {[34mscheduler_job_runner.py:[0m411} INFO[0m - 1 tasks up for execution:
	<TaskInstance: two_task_dag.Bash_task_0 manual__2024-04-22T14:32:06.928889+00:00 [scheduled]>[0m
[[34m2024-04-22T14:32:07.343+0000[0m] {[34mscheduler_job_runner.py:[0m476} INFO[0m - DAG two_task_dag has 0/16 running and queued tasks[0m
[[34m2024-04-22T14:32:07.344+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: two_task_dag.Bash_task_0 manual__2024-04-22T14:32:06.928889+00:00 [scheduled]>[0m
[[34m2024-04-22T14:32:07.346+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='two_task_dag', task_id='Bash_task_0', run_id='manual__2024-04-22T14:32:06.928889+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-04-22T14:32:07.346+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'two_task_dag', 'Bash_task_0', 'manual__2024-04-22T14:32:06.928889+00:00', '--local', '--subdir', 'DAGS_FOLDER/two_task_dag.py'][0m
[[34m2024-04-22T14:32:07.386+0000[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'two_task_dag', 'Bash_task_0', 'manual__2024-04-22T14:32:06.928889+00:00', '--local', '--subdir', 'DAGS_FOLDER/two_task_dag.py'][0m
[[34m2024-04-22T14:32:08.157+0000[0m] {[34mdagbag.py:[0m541} INFO[0m - Filling up the DagBag from /workspaces/hands-on-introduction-data-engineering-4395021/airflow/dags/two_task_dag.py[0m
[[34m2024-04-22T14:32:08.704+0000[0m] {[34mtask_command.py:[0m410} INFO[0m - Running <TaskInstance: two_task_dag.Bash_task_0 manual__2024-04-22T14:32:06.928889+00:00 [queued]> on host codespaces-225cfe[0m
[[34m2024-04-22T14:32:09.384+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='two_task_dag', task_id='Bash_task_0', run_id='manual__2024-04-22T14:32:06.928889+00:00', try_number=1, map_index=-1)[0m
[[34m2024-04-22T14:32:09.390+0000[0m] {[34mscheduler_job_runner.py:[0m713} INFO[0m - TaskInstance Finished: dag_id=two_task_dag, task_id=Bash_task_0, run_id=manual__2024-04-22T14:32:06.928889+00:00, map_index=-1, run_start_date=2024-04-22 14:32:08.777801+00:00, run_end_date=2024-04-22 14:32:09.009855+00:00, run_duration=0.232054, state=success, executor_state=success, try_number=1, max_tries=0, job_id=2, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2024-04-22 14:32:07.344571+00:00, queued_by_job_id=1, pid=13463[0m
[[34m2024-04-22T14:32:09.482+0000[0m] {[34mscheduler_job_runner.py:[0m411} INFO[0m - 1 tasks up for execution:
	<TaskInstance: two_task_dag.Bash_task_1 manual__2024-04-22T14:32:06.928889+00:00 [scheduled]>[0m
[[34m2024-04-22T14:32:09.482+0000[0m] {[34mscheduler_job_runner.py:[0m476} INFO[0m - DAG two_task_dag has 0/16 running and queued tasks[0m
[[34m2024-04-22T14:32:09.483+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: two_task_dag.Bash_task_1 manual__2024-04-22T14:32:06.928889+00:00 [scheduled]>[0m
[[34m2024-04-22T14:32:09.484+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='two_task_dag', task_id='Bash_task_1', run_id='manual__2024-04-22T14:32:06.928889+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-04-22T14:32:09.484+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'two_task_dag', 'Bash_task_1', 'manual__2024-04-22T14:32:06.928889+00:00', '--local', '--subdir', 'DAGS_FOLDER/two_task_dag.py'][0m
[[34m2024-04-22T14:32:09.516+0000[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'two_task_dag', 'Bash_task_1', 'manual__2024-04-22T14:32:06.928889+00:00', '--local', '--subdir', 'DAGS_FOLDER/two_task_dag.py'][0m
[[34m2024-04-22T14:32:10.305+0000[0m] {[34mdagbag.py:[0m541} INFO[0m - Filling up the DagBag from /workspaces/hands-on-introduction-data-engineering-4395021/airflow/dags/two_task_dag.py[0m
[[34m2024-04-22T14:32:10.831+0000[0m] {[34mtask_command.py:[0m410} INFO[0m - Running <TaskInstance: two_task_dag.Bash_task_1 manual__2024-04-22T14:32:06.928889+00:00 [queued]> on host codespaces-225cfe[0m
[[34m2024-04-22T14:32:16.474+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='two_task_dag', task_id='Bash_task_1', run_id='manual__2024-04-22T14:32:06.928889+00:00', try_number=1, map_index=-1)[0m
[[34m2024-04-22T14:32:16.478+0000[0m] {[34mscheduler_job_runner.py:[0m713} INFO[0m - TaskInstance Finished: dag_id=two_task_dag, task_id=Bash_task_1, run_id=manual__2024-04-22T14:32:06.928889+00:00, map_index=-1, run_start_date=2024-04-22 14:32:10.913158+00:00, run_end_date=2024-04-22 14:32:16.151407+00:00, run_duration=5.238249, state=success, executor_state=success, try_number=1, max_tries=0, job_id=3, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-04-22 14:32:09.483392+00:00, queued_by_job_id=1, pid=13472[0m
[[34m2024-04-22T14:32:16.541+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun two_task_dag @ 2024-04-22 14:32:06.928889+00:00: manual__2024-04-22T14:32:06.928889+00:00, state:running, queued_at: 2024-04-22 14:32:06.969433+00:00. externally triggered: True> successful[0m
[[34m2024-04-22T14:32:16.542+0000[0m] {[34mdagrun.py:[0m681} INFO[0m - DagRun Finished: dag_id=two_task_dag, execution_date=2024-04-22 14:32:06.928889+00:00, run_id=manual__2024-04-22T14:32:06.928889+00:00, run_start_date=2024-04-22 14:32:07.251575+00:00, run_end_date=2024-04-22 14:32:16.542379+00:00, run_duration=9.290804, state=success, external_trigger=True, run_type=manual, data_interval_start=2024-04-22 14:32:06.928889+00:00, data_interval_end=2024-04-22 14:32:06.928889+00:00, dag_hash=953a3b5688eba243dde30fe6cfdcc603[0m
[[34m2024-04-22T14:32:20.816+0000[0m] {[34mscheduler_job_runner.py:[0m411} INFO[0m - 1 tasks up for execution:
	<TaskInstance: two_task_dag.Bash_task_0 manual__2024-04-22T14:32:19.602807+00:00 [scheduled]>[0m
[[34m2024-04-22T14:32:20.817+0000[0m] {[34mscheduler_job_runner.py:[0m476} INFO[0m - DAG two_task_dag has 0/16 running and queued tasks[0m
[[34m2024-04-22T14:32:20.817+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: two_task_dag.Bash_task_0 manual__2024-04-22T14:32:19.602807+00:00 [scheduled]>[0m
[[34m2024-04-22T14:32:20.818+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='two_task_dag', task_id='Bash_task_0', run_id='manual__2024-04-22T14:32:19.602807+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-04-22T14:32:20.818+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'two_task_dag', 'Bash_task_0', 'manual__2024-04-22T14:32:19.602807+00:00', '--local', '--subdir', 'DAGS_FOLDER/two_task_dag.py'][0m
[[34m2024-04-22T14:32:20.847+0000[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'two_task_dag', 'Bash_task_0', 'manual__2024-04-22T14:32:19.602807+00:00', '--local', '--subdir', 'DAGS_FOLDER/two_task_dag.py'][0m
[[34m2024-04-22T14:32:21.613+0000[0m] {[34mdagbag.py:[0m541} INFO[0m - Filling up the DagBag from /workspaces/hands-on-introduction-data-engineering-4395021/airflow/dags/two_task_dag.py[0m
[[34m2024-04-22T14:32:22.173+0000[0m] {[34mtask_command.py:[0m410} INFO[0m - Running <TaskInstance: two_task_dag.Bash_task_0 manual__2024-04-22T14:32:19.602807+00:00 [queued]> on host codespaces-225cfe[0m
[[34m2024-04-22T14:32:22.928+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='two_task_dag', task_id='Bash_task_0', run_id='manual__2024-04-22T14:32:19.602807+00:00', try_number=1, map_index=-1)[0m
[[34m2024-04-22T14:32:22.931+0000[0m] {[34mscheduler_job_runner.py:[0m713} INFO[0m - TaskInstance Finished: dag_id=two_task_dag, task_id=Bash_task_0, run_id=manual__2024-04-22T14:32:19.602807+00:00, map_index=-1, run_start_date=2024-04-22 14:32:22.244135+00:00, run_end_date=2024-04-22 14:32:22.492305+00:00, run_duration=0.24817, state=success, executor_state=success, try_number=1, max_tries=0, job_id=4, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2024-04-22 14:32:20.817611+00:00, queued_by_job_id=1, pid=13543[0m
[[34m2024-04-22T14:32:23.028+0000[0m] {[34mscheduler_job_runner.py:[0m411} INFO[0m - 1 tasks up for execution:
	<TaskInstance: two_task_dag.Bash_task_1 manual__2024-04-22T14:32:19.602807+00:00 [scheduled]>[0m
[[34m2024-04-22T14:32:23.028+0000[0m] {[34mscheduler_job_runner.py:[0m476} INFO[0m - DAG two_task_dag has 0/16 running and queued tasks[0m
[[34m2024-04-22T14:32:23.028+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: two_task_dag.Bash_task_1 manual__2024-04-22T14:32:19.602807+00:00 [scheduled]>[0m
[[34m2024-04-22T14:32:23.029+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='two_task_dag', task_id='Bash_task_1', run_id='manual__2024-04-22T14:32:19.602807+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-04-22T14:32:23.030+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'two_task_dag', 'Bash_task_1', 'manual__2024-04-22T14:32:19.602807+00:00', '--local', '--subdir', 'DAGS_FOLDER/two_task_dag.py'][0m
[[34m2024-04-22T14:32:23.059+0000[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'two_task_dag', 'Bash_task_1', 'manual__2024-04-22T14:32:19.602807+00:00', '--local', '--subdir', 'DAGS_FOLDER/two_task_dag.py'][0m
[[34m2024-04-22T14:32:23.868+0000[0m] {[34mdagbag.py:[0m541} INFO[0m - Filling up the DagBag from /workspaces/hands-on-introduction-data-engineering-4395021/airflow/dags/two_task_dag.py[0m
[[34m2024-04-22T14:32:24.411+0000[0m] {[34mtask_command.py:[0m410} INFO[0m - Running <TaskInstance: two_task_dag.Bash_task_1 manual__2024-04-22T14:32:19.602807+00:00 [queued]> on host codespaces-225cfe[0m
[[34m2024-04-22T14:32:30.069+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='two_task_dag', task_id='Bash_task_1', run_id='manual__2024-04-22T14:32:19.602807+00:00', try_number=1, map_index=-1)[0m
[[34m2024-04-22T14:32:30.072+0000[0m] {[34mscheduler_job_runner.py:[0m713} INFO[0m - TaskInstance Finished: dag_id=two_task_dag, task_id=Bash_task_1, run_id=manual__2024-04-22T14:32:19.602807+00:00, map_index=-1, run_start_date=2024-04-22 14:32:24.482485+00:00, run_end_date=2024-04-22 14:32:29.750845+00:00, run_duration=5.26836, state=success, executor_state=success, try_number=1, max_tries=0, job_id=5, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-04-22 14:32:23.029067+00:00, queued_by_job_id=1, pid=13558[0m
[[34m2024-04-22T14:32:30.254+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun two_task_dag @ 2024-04-22 14:32:19.602807+00:00: manual__2024-04-22T14:32:19.602807+00:00, state:running, queued_at: 2024-04-22 14:32:19.613283+00:00. externally triggered: True> successful[0m
[[34m2024-04-22T14:32:30.254+0000[0m] {[34mdagrun.py:[0m681} INFO[0m - DagRun Finished: dag_id=two_task_dag, execution_date=2024-04-22 14:32:19.602807+00:00, run_id=manual__2024-04-22T14:32:19.602807+00:00, run_start_date=2024-04-22 14:32:20.742788+00:00, run_end_date=2024-04-22 14:32:30.254926+00:00, run_duration=9.512138, state=success, external_trigger=True, run_type=manual, data_interval_start=2024-04-22 14:32:19.602807+00:00, data_interval_end=2024-04-22 14:32:19.602807+00:00, dag_hash=953a3b5688eba243dde30fe6cfdcc603[0m
[[34m2024-04-22T14:35:25.969+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2024-04-22T14:40:25.998+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2024-04-22T14:45:26.029+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2024-04-22T14:50:26.055+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2024-04-22T14:55:26.091+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2024-04-22T14:58:12.834+0000[0m] {[34mscheduler_job_runner.py:[0m247} INFO[0m - Exiting gracefully upon receiving signal 15[0m
[[34m2024-04-22T14:58:13.836+0000[0m] {[34mprocess_utils.py:[0m131} INFO[0m - Sending Signals.SIGTERM to group 12628. PIDs of all processes in the group: [12628][0m
[[34m2024-04-22T14:58:13.837+0000[0m] {[34mprocess_utils.py:[0m86} INFO[0m - Sending the signal Signals.SIGTERM to group 12628[0m
[[34m2024-04-22T14:58:14.090+0000[0m] {[34mprocess_utils.py:[0m79} INFO[0m - Process psutil.Process(pid=12628, status='terminated', exitcode=0, started='14:30:25') (12628) terminated with exit code 0[0m
[[34m2024-04-22T14:58:14.092+0000[0m] {[34mprocess_utils.py:[0m131} INFO[0m - Sending Signals.SIGTERM to group 12628. PIDs of all processes in the group: [][0m
[[34m2024-04-22T14:58:14.093+0000[0m] {[34mprocess_utils.py:[0m86} INFO[0m - Sending the signal Signals.SIGTERM to group 12628[0m
[[34m2024-04-22T14:58:14.093+0000[0m] {[34mprocess_utils.py:[0m100} INFO[0m - Sending the signal Signals.SIGTERM to process 12628 as process group is missing.[0m
[[34m2024-04-22T14:58:14.093+0000[0m] {[34mscheduler_job_runner.py:[0m864} INFO[0m - Exited execute loop[0m
