[[34m2024-04-23T17:49:09.793+0000[0m] {[34mscheduler_job_runner.py:[0m788} INFO[0m - Starting the scheduler[0m
[[34m2024-04-23T17:49:09.793+0000[0m] {[34mscheduler_job_runner.py:[0m795} INFO[0m - Processing each file at most -1 times[0m
[[34m2024-04-23T17:49:09.798+0000[0m] {[34mmanager.py:[0m165} INFO[0m - Launched DagFileProcessorManager with pid: 55246[0m
[[34m2024-04-23T17:49:09.799+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2024-04-23T17:49:09.802+0000[0m] {[34msettings.py:[0m60} INFO[0m - Configured default timezone Timezone('UTC')[0m
[2024-04-23T17:49:09.821+0000] {manager.py:411} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[[34m2024-04-23T17:54:09.933+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2024-04-23T17:59:09.961+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2024-04-23T18:04:10.237+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2024-04-23T18:09:10.249+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2024-04-23T18:14:10.284+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2024-04-23T18:19:10.311+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2024-04-23T18:24:10.337+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2024-04-23T18:26:47.188+0000[0m] {[34mscheduler_job_runner.py:[0m411} INFO[0m - 1 tasks up for execution:
	<TaskInstance: transform_dag.transform_task manual__2024-04-23T18:26:46.790952+00:00 [scheduled]>[0m
[[34m2024-04-23T18:26:47.188+0000[0m] {[34mscheduler_job_runner.py:[0m476} INFO[0m - DAG transform_dag has 0/16 running and queued tasks[0m
[[34m2024-04-23T18:26:47.188+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: transform_dag.transform_task manual__2024-04-23T18:26:46.790952+00:00 [scheduled]>[0m
[[34m2024-04-23T18:26:47.190+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='transform_dag', task_id='transform_task', run_id='manual__2024-04-23T18:26:46.790952+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-04-23T18:26:47.190+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'transform_dag', 'transform_task', 'manual__2024-04-23T18:26:46.790952+00:00', '--local', '--subdir', 'DAGS_FOLDER/transform_dag.py'][0m
[[34m2024-04-23T18:26:47.219+0000[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'transform_dag', 'transform_task', 'manual__2024-04-23T18:26:46.790952+00:00', '--local', '--subdir', 'DAGS_FOLDER/transform_dag.py'][0m
[[34m2024-04-23T18:26:48.014+0000[0m] {[34mdagbag.py:[0m541} INFO[0m - Filling up the DagBag from /workspaces/hands-on-introduction-data-engineering-4395021/airflow/dags/transform_dag.py[0m
[[34m2024-04-23T18:26:48.836+0000[0m] {[34mtask_command.py:[0m410} INFO[0m - Running <TaskInstance: transform_dag.transform_task manual__2024-04-23T18:26:46.790952+00:00 [queued]> on host codespaces-225cfe[0m
[[34m2024-04-23T18:26:49.470+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='transform_dag', task_id='transform_task', run_id='manual__2024-04-23T18:26:46.790952+00:00', try_number=1, map_index=-1)[0m
[[34m2024-04-23T18:26:49.476+0000[0m] {[34mscheduler_job_runner.py:[0m713} INFO[0m - TaskInstance Finished: dag_id=transform_dag, task_id=transform_task, run_id=manual__2024-04-23T18:26:46.790952+00:00, map_index=-1, run_start_date=2024-04-23 18:26:48.899786+00:00, run_end_date=2024-04-23 18:26:49.094788+00:00, run_duration=0.195002, state=failed, executor_state=success, try_number=1, max_tries=0, job_id=2, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-04-23 18:26:47.188916+00:00, queued_by_job_id=1, pid=69929[0m
[[34m2024-04-23T18:26:49.505+0000[0m] {[34mdagrun.py:[0m609} ERROR[0m - Marking run <DagRun transform_dag @ 2024-04-23 18:26:46.790952+00:00: manual__2024-04-23T18:26:46.790952+00:00, state:running, queued_at: 2024-04-23 18:26:46.832851+00:00. externally triggered: True> failed[0m
[[34m2024-04-23T18:26:49.506+0000[0m] {[34mdagrun.py:[0m681} INFO[0m - DagRun Finished: dag_id=transform_dag, execution_date=2024-04-23 18:26:46.790952+00:00, run_id=manual__2024-04-23T18:26:46.790952+00:00, run_start_date=2024-04-23 18:26:47.114297+00:00, run_end_date=2024-04-23 18:26:49.505980+00:00, run_duration=2.391683, state=failed, external_trigger=True, run_type=manual, data_interval_start=2024-04-23 18:26:46.790952+00:00, data_interval_end=2024-04-23 18:26:46.790952+00:00, dag_hash=3ce48d98050b57f4e240f966c9c0eb0f[0m
[[34m2024-04-23T18:27:52.231+0000[0m] {[34mscheduler_job_runner.py:[0m411} INFO[0m - 1 tasks up for execution:
	<TaskInstance: transform_dag.transform_task manual__2024-04-23T18:27:51.371554+00:00 [scheduled]>[0m
[[34m2024-04-23T18:27:52.231+0000[0m] {[34mscheduler_job_runner.py:[0m476} INFO[0m - DAG transform_dag has 0/16 running and queued tasks[0m
[[34m2024-04-23T18:27:52.231+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: transform_dag.transform_task manual__2024-04-23T18:27:51.371554+00:00 [scheduled]>[0m
[[34m2024-04-23T18:27:52.232+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='transform_dag', task_id='transform_task', run_id='manual__2024-04-23T18:27:51.371554+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-04-23T18:27:52.232+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'transform_dag', 'transform_task', 'manual__2024-04-23T18:27:51.371554+00:00', '--local', '--subdir', 'DAGS_FOLDER/transform_dag.py'][0m
[[34m2024-04-23T18:27:52.261+0000[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'transform_dag', 'transform_task', 'manual__2024-04-23T18:27:51.371554+00:00', '--local', '--subdir', 'DAGS_FOLDER/transform_dag.py'][0m
[[34m2024-04-23T18:27:53.023+0000[0m] {[34mdagbag.py:[0m541} INFO[0m - Filling up the DagBag from /workspaces/hands-on-introduction-data-engineering-4395021/airflow/dags/transform_dag.py[0m
[[34m2024-04-23T18:27:53.844+0000[0m] {[34mtask_command.py:[0m410} INFO[0m - Running <TaskInstance: transform_dag.transform_task manual__2024-04-23T18:27:51.371554+00:00 [queued]> on host codespaces-225cfe[0m
[[34m2024-04-23T18:27:54.477+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='transform_dag', task_id='transform_task', run_id='manual__2024-04-23T18:27:51.371554+00:00', try_number=1, map_index=-1)[0m
[[34m2024-04-23T18:27:54.480+0000[0m] {[34mscheduler_job_runner.py:[0m713} INFO[0m - TaskInstance Finished: dag_id=transform_dag, task_id=transform_task, run_id=manual__2024-04-23T18:27:51.371554+00:00, map_index=-1, run_start_date=2024-04-23 18:27:53.913713+00:00, run_end_date=2024-04-23 18:27:54.120755+00:00, run_duration=0.207042, state=failed, executor_state=success, try_number=1, max_tries=0, job_id=3, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-04-23 18:27:52.231952+00:00, queued_by_job_id=1, pid=70243[0m
[[34m2024-04-23T18:27:54.919+0000[0m] {[34mdagrun.py:[0m609} ERROR[0m - Marking run <DagRun transform_dag @ 2024-04-23 18:27:51.371554+00:00: manual__2024-04-23T18:27:51.371554+00:00, state:running, queued_at: 2024-04-23 18:27:51.380095+00:00. externally triggered: True> failed[0m
[[34m2024-04-23T18:27:54.920+0000[0m] {[34mdagrun.py:[0m681} INFO[0m - DagRun Finished: dag_id=transform_dag, execution_date=2024-04-23 18:27:51.371554+00:00, run_id=manual__2024-04-23T18:27:51.371554+00:00, run_start_date=2024-04-23 18:27:52.159628+00:00, run_end_date=2024-04-23 18:27:54.920254+00:00, run_duration=2.760626, state=failed, external_trigger=True, run_type=manual, data_interval_start=2024-04-23 18:27:51.371554+00:00, data_interval_end=2024-04-23 18:27:51.371554+00:00, dag_hash=3ce48d98050b57f4e240f966c9c0eb0f[0m
[[34m2024-04-23T18:29:10.364+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2024-04-23T18:34:10.391+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2024-04-23T18:34:53.760+0000[0m] {[34mscheduler_job_runner.py:[0m411} INFO[0m - 1 tasks up for execution:
	<TaskInstance: transform_dag.transform_task manual__2024-04-23T18:34:52.150784+00:00 [scheduled]>[0m
[[34m2024-04-23T18:34:53.760+0000[0m] {[34mscheduler_job_runner.py:[0m476} INFO[0m - DAG transform_dag has 0/16 running and queued tasks[0m
[[34m2024-04-23T18:34:53.761+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: transform_dag.transform_task manual__2024-04-23T18:34:52.150784+00:00 [scheduled]>[0m
[[34m2024-04-23T18:34:53.762+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='transform_dag', task_id='transform_task', run_id='manual__2024-04-23T18:34:52.150784+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-04-23T18:34:53.762+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'transform_dag', 'transform_task', 'manual__2024-04-23T18:34:52.150784+00:00', '--local', '--subdir', 'DAGS_FOLDER/transform_dag.py'][0m
[[34m2024-04-23T18:34:53.790+0000[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'transform_dag', 'transform_task', 'manual__2024-04-23T18:34:52.150784+00:00', '--local', '--subdir', 'DAGS_FOLDER/transform_dag.py'][0m
[[34m2024-04-23T18:34:54.560+0000[0m] {[34mdagbag.py:[0m541} INFO[0m - Filling up the DagBag from /workspaces/hands-on-introduction-data-engineering-4395021/airflow/dags/transform_dag.py[0m
[[34m2024-04-23T18:34:55.376+0000[0m] {[34mtask_command.py:[0m410} INFO[0m - Running <TaskInstance: transform_dag.transform_task manual__2024-04-23T18:34:52.150784+00:00 [queued]> on host codespaces-225cfe[0m
[[34m2024-04-23T18:34:56.024+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='transform_dag', task_id='transform_task', run_id='manual__2024-04-23T18:34:52.150784+00:00', try_number=1, map_index=-1)[0m
[[34m2024-04-23T18:34:56.027+0000[0m] {[34mscheduler_job_runner.py:[0m713} INFO[0m - TaskInstance Finished: dag_id=transform_dag, task_id=transform_task, run_id=manual__2024-04-23T18:34:52.150784+00:00, map_index=-1, run_start_date=2024-04-23 18:34:55.439483+00:00, run_end_date=2024-04-23 18:34:55.660507+00:00, run_duration=0.221024, state=success, executor_state=success, try_number=1, max_tries=0, job_id=4, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2024-04-23 18:34:53.761494+00:00, queued_by_job_id=1, pid=72588[0m
[[34m2024-04-23T18:34:56.096+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun transform_dag @ 2024-04-23 18:34:52.150784+00:00: manual__2024-04-23T18:34:52.150784+00:00, state:running, queued_at: 2024-04-23 18:34:52.155064+00:00. externally triggered: True> successful[0m
[[34m2024-04-23T18:34:56.096+0000[0m] {[34mdagrun.py:[0m681} INFO[0m - DagRun Finished: dag_id=transform_dag, execution_date=2024-04-23 18:34:52.150784+00:00, run_id=manual__2024-04-23T18:34:52.150784+00:00, run_start_date=2024-04-23 18:34:53.688078+00:00, run_end_date=2024-04-23 18:34:56.096907+00:00, run_duration=2.408829, state=success, external_trigger=True, run_type=manual, data_interval_start=2024-04-23 18:34:52.150784+00:00, data_interval_end=2024-04-23 18:34:52.150784+00:00, dag_hash=3ce48d98050b57f4e240f966c9c0eb0f[0m
[[34m2024-04-23T18:38:11.351+0000[0m] {[34mscheduler_job_runner.py:[0m247} INFO[0m - Exiting gracefully upon receiving signal 15[0m
[[34m2024-04-23T18:38:12.355+0000[0m] {[34mprocess_utils.py:[0m131} INFO[0m - Sending Signals.SIGTERM to group 55246. PIDs of all processes in the group: [55246][0m
[[34m2024-04-23T18:38:12.355+0000[0m] {[34mprocess_utils.py:[0m86} INFO[0m - Sending the signal Signals.SIGTERM to group 55246[0m
[[34m2024-04-23T18:38:12.567+0000[0m] {[34mprocess_utils.py:[0m79} INFO[0m - Process psutil.Process(pid=55246, status='terminated', exitcode=0, started='17:49:09') (55246) terminated with exit code 0[0m
[[34m2024-04-23T18:38:12.570+0000[0m] {[34mprocess_utils.py:[0m131} INFO[0m - Sending Signals.SIGTERM to group 55246. PIDs of all processes in the group: [][0m
[[34m2024-04-23T18:38:12.570+0000[0m] {[34mprocess_utils.py:[0m86} INFO[0m - Sending the signal Signals.SIGTERM to group 55246[0m
[[34m2024-04-23T18:38:12.570+0000[0m] {[34mprocess_utils.py:[0m100} INFO[0m - Sending the signal Signals.SIGTERM to process 55246 as process group is missing.[0m
[[34m2024-04-23T18:38:12.571+0000[0m] {[34mscheduler_job_runner.py:[0m864} INFO[0m - Exited execute loop[0m
